{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"../resources/./music_2.npy\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_3248376',\n",
       " 'artist_4660',\n",
       " 'track_68116150',\n",
       " 'artist_210',\n",
       " 'track_68116150',\n",
       " 'artist_210',\n",
       " 'track_3169189',\n",
       " 'artist_7188',\n",
       " 'track_6523608',\n",
       " 'artist_2961',\n",
       " 'track_407020492',\n",
       " 'artist_2961',\n",
       " 'track_6523613',\n",
       " 'artist_2961',\n",
       " 'track_348627211',\n",
       " 'artist_396485',\n",
       " 'track_348627221',\n",
       " 'artist_396485',\n",
       " 'track_348627231',\n",
       " 'artist_396485',\n",
       " 'track_348627241',\n",
       " 'artist_396485',\n",
       " 'track_348627251',\n",
       " 'artist_2961',\n",
       " 'track_348627261',\n",
       " 'artist_2961',\n",
       " 'track_348627271',\n",
       " 'artist_2961',\n",
       " 'track_348627281',\n",
       " 'artist_2961',\n",
       " 'track_348627291',\n",
       " 'artist_2961']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# récupération uniquement des identifiant de morceaux // suppression des identifiant d'artiste\n",
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338509"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de morceaux != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_3248376',\n",
       " 'track_68116150',\n",
       " 'track_68116150',\n",
       " 'track_3169189',\n",
       " 'track_6523608',\n",
       " 'track_407020492',\n",
       " 'track_6523613',\n",
       " 'track_348627211',\n",
       " 'track_348627221',\n",
       " 'track_348627231',\n",
       " 'track_348627241',\n",
       " 'track_348627251',\n",
       " 'track_348627261',\n",
       " 'track_348627271',\n",
       " 'track_348627281',\n",
       " 'track_348627291']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_track[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_counts = dict((track,0) for track in tracks)\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtrage des morceaux très peu fréquents\n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 7, playlist)) for playlist in playlist_track]\n",
    "track_f = np.unique(np.concatenate(playlist_track_filter))\n",
    "Vt = len(track_f)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track_100001884'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construction d'un dict id_morceaux id [0,Vt]\n",
    "track_dict = dict((track_f[i], i) for i in range(0, Vt))\n",
    "# conversion des playlist en liste d'entier\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_dict['track_100001884']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10091, 18411, 18411, 10073, 17882]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_num_track[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_3248376',\n",
       " 'track_68116150',\n",
       " 'track_68116150',\n",
       " 'track_3169189',\n",
       " 'track_6523608']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_track_filter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyper-paramètres de word2vec :\n",
    "# dimension de l'espace latent\n",
    "vector_dim = 50\n",
    "# taille de la fenêtre de voisinage\n",
    "window_width = 5\n",
    "# sur-échantillonage des exemples négatifs\n",
    "neg_sample = 4.\n",
    "# taille des mini-batch\n",
    "min_batch_size = 50\n",
    "# coeff pour la loi de tirage des exemple negatif\n",
    "samp_coef = -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comptage du nombre d'occurences des morceaux dans les playlist filtrées\n",
    "tracks_counts_f = dict((track_f[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track_filter:\n",
    "    for t in p:\n",
    "        tracks_counts_f[t]=tracks_counts_f[t]+1;\n",
    "# construction de la table de tirage des morceaux pour les exmeple negatif en utilisant ces fréquences\n",
    "spt_tracks=np.array(list(map(lambda a:tracks_counts_f[a],track_f)),np.float)\n",
    "sptn_tracks=np.power(spt_tracks,samp_coef)\n",
    "sptn_tracks=sptn_tracks/np.sum(sptn_tracks)\n",
    "sptn_tracks=np.cumsum(np.sort(sptn_tracks)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2inl2/efurreed/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# construction du réseau word2vec\n",
    "\n",
    "# entrée deux entier (couple de morceaux)\n",
    "input_target_t = Input((1,), dtype='int32')\n",
    "input_context_t = Input((1,), dtype='int32')\n",
    "\n",
    "# définition de l'embeding\n",
    "embedding_t_t = Embedding(Vt, vector_dim, input_length=1, name='embedding_t')\n",
    "# projection du premier morceau\n",
    "target_t = embedding_t_t(input_target_t)\n",
    "target_t = Reshape((vector_dim, 1))(target_t)\n",
    "\n",
    "# projection du second morceaux\n",
    "context_t = embedding_t_t(input_context_t)\n",
    "context_t = Reshape((vector_dim, 1))(context_t)\n",
    "\n",
    "# calcul de la sortie\n",
    "dot_product_t = Dot(axes=0)([target_t, context_t])\n",
    "dot_product_t = Reshape((1,))(dot_product_t)\n",
    "output_t = Dense(1, activation='sigmoid',name=\"classif\")(dot_product_t)\n",
    "\n",
    "# definition du modèle\n",
    "SkipGram_t = Model(inputs=[input_target_t, input_context_t], outputs=output_t)\n",
    "SkipGram_t.compile(loss='binary_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# définition du générateur de couple de morceaux (y=0 <-> aléatoire, y=1 <-> proche dans une playlist)\n",
    "import random\n",
    "def track_ns_generator(corpus_num,nbm):\n",
    "    while 1:\n",
    "        Data=[]\n",
    "        Labels=[]\n",
    "        for i, doc in enumerate(random.sample(corpus_num,nbm)):\n",
    "            data, labels = skipgrams(sequence=doc, vocabulary_size=Vt, window_size=window_width, negative_samples=neg_sample,sampling_table=sptn_tracks)\n",
    "            if (len(data)>0):\n",
    "                Data.append(np.array(data, dtype=np.int32))\n",
    "                Labels.append(np.array(labels, dtype=np.int32))\n",
    "        Data=np.concatenate(Data)\n",
    "        Labels=np.concatenate(Labels)\n",
    "        x=[Data[:,0],Data[:,1]]\n",
    "        y=Labels\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensemble de test et d'apprentissage\n",
    "index_tst = np.random.choice(100000,10000)\n",
    "index_app  = np.setdiff1d(range(100000),index_tst)\n",
    "\n",
    "play_app   = [corpus_num_track[i] for i in index_app]\n",
    "play_tst  = [corpus_num_track[i] for i in index_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2inl2/efurreed/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.6649\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.6090\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.5453\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4987\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4721\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4455\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4267\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4096\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.3935\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.3768\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.3662\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.3496\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.3369\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.3266\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.3203\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.3089\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.3061\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2968\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2908\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.2776\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.2780\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.2725\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2670\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2631\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.2587\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2531\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2475\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2491\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2454\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2429\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2397\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.2347\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2316\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2322\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2300\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2287\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2264\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.2174\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2191\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2154\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2166\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2183\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2142\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2173\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2110\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2117\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.2145\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2083\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.2056\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.2100\n"
     ]
    }
   ],
   "source": [
    "hist=SkipGram_t.fit_generator(track_ns_generator(play_app,min_batch_size),200,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# récupérations des positions des morceaux dans l'espace de projection\n",
    "vectors_tracks = SkipGram_t.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fonction retournant les indices des s plus proches voisins des seeds dans la matrice X\n",
    "# a vous de jouer avec pairwise_distances, np.min, np.argsort,...\n",
    "def predict(seeds,s,X, metrics=\"cosine\"):\n",
    "    V = X.shape[0]\n",
    "    D = pairwise_distances(X[seeds,:],X[np.setdiff1d(range(V),seeds),:],metrics)\n",
    "    return np.argsort(np.min(D,0))[:s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3548,  6332,  3546, 21905])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemple pour 4 suggestions avec les 2 premiers morceaux en seeds \n",
    "pr=predict([0,1],4,vectors_tracks)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(range(10), [0,1,48, 9, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00853987],\n",
       "       [0.00853987, 0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances([[1,2,3],[1,2,4]], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# estimation des performances\n",
    "# hit@10\n",
    "# nombre de bonne prediction\n",
    "goodpred = []\n",
    "# nombre de predictions faites\n",
    "nbpred   = []\n",
    "# pour chaque playlist\n",
    "for p in play_tst:\n",
    "    # si au moins deux chansons\n",
    "    if (len(p)>1):\n",
    "        # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "        seeds  = p[:np.min([5,len(p)-1])]\n",
    "        # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "        topred = p[np.min([5,len(p)-1]):]\n",
    "        # construction des suggestions 10 suggestions par morceaux a predire\n",
    "        prediction = predict(seeds,10*len(topred),vectors_tracks)\n",
    "        # comptage du nombre de morceaux présent dans nos suggestions\n",
    "        goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "        # stockage du nombre de predictions\n",
    "        nbpred.append(len(topred))\n",
    "# proportions de morceux présents dans nos suggestions\n",
    "hitat10 = np.sum(goodpred)/np.sum(nbpred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ici commence le formidable travail de **Maxme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_pairwise(metrics='euclidean'):\n",
    "    # nombre de bonne prediction\n",
    "    goodpred = []\n",
    "    # nombre de predictions faites\n",
    "    nbpred   = []\n",
    "    # pour chaque playlist\n",
    "    for p in play_tst:\n",
    "        # si au moins deux chansons\n",
    "        if (len(p)>1):\n",
    "            # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "            seeds  = p[:np.min([5,len(p)-1])]\n",
    "            # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "            topred = p[np.min([5,len(p)-1]):]\n",
    "            # construction des suggestions 10 suggestions par morceaux a predire\n",
    "            prediction = predict(seeds,10*len(topred),vectors_tracks, metrics)\n",
    "            # comptage du nombre de morceaux présent dans nos suggestions\n",
    "            goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "            # stockage du nombre de predictions\n",
    "            nbpred.append(len(topred))\n",
    "    # proportions de morceux présents dans nos suggestions\n",
    "    return np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "hitat10_euclidean = test_pairwise()\n",
    "\n",
    "#Cosine\n",
    "hitat10_cosine = test_pairwise('cosine')\n",
    "\n",
    "#manhattan\n",
    "hitat10_manhattan = test_pairwise('manhattan')\n",
    "\n",
    "#blockcity\n",
    "hitat10_manhattan = test_pairwise('manhattan')\n",
    "\n",
    "#manhattan\n",
    "hitat10_manhattan = test_pairwise('manhattan')\n",
    "\n",
    "#manhattan\n",
    "hitat10_manhattan = test_pairwise('manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_VALID_METRICS = ['euclidean', 'cosine', 'manhattan']\n",
    "hitat10_results = dict((metric, test_pairwise(metric)) for metric in _VALID_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hitat10_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_hitat10 = sorted(hitat10_results.items(), key=operator.itemgetter(1))\n",
    "sorted_hitat10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Dataset\n",
    "values = []\n",
    "labels = []\n",
    "for item in sorted_hitat10:\n",
    "    values.append(item[1])\n",
    "    labels.append(item[0])\n",
    "\n",
    "# Create bars and choose color\n",
    "y_pos = np.arange(len(labels))\n",
    "plt.bar(y_pos, values, color = (0.5,0.1,0.5,0.6))\n",
    "\n",
    "# Add title and axis names\n",
    "plt.title('Hitat10 results for different metrics')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('score')\n",
    " \n",
    "# Limits for the Y axis\n",
    "plt.ylim(0, np.max(values) * 1.5)\n",
    " \n",
    "# Create names\n",
    "plt.xticks(y_pos, labels)\n",
    " \n",
    "# Show graphic\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "samples = [[0,0,2], [1,0,0], [0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(2)\n",
    "neigh.fit(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = [[0,0,1.3],[1,1,1]]\n",
    "nbrs = neigh.kneighbors(l, 2, return_distance=False)\n",
    "np.asarray(nbrs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(5, algorithm='auto', metric='yule')\n",
    "neigh.fit(vectors_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "play_0 = play_tst[0]\n",
    "nbrs = neigh.kneighbors(vectors_tracks[play_0, :], 20, return_distance=False)\n",
    "#prediction = predict(seeds,10*len(topred),vectors_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ll = [[1,2,3],[4,5,6],[9,8,5,5]]\n",
    "list(map(lambda x : x[1:], ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(seeds,s,X, metrics=\"cosine\"):\n",
    "    V = X.shape[0]\n",
    "    D = pairwise_distances(X[seeds,:],X[np.setdiff1d(range(V),seeds),:],metrics)\n",
    "    return np.argsort(np.min(D,0))[:s]\n",
    "\n",
    "\n",
    "def test_kneighbors():\n",
    "    # nombre de bonne prediction\n",
    "    goodpred = []\n",
    "    # nombre de predictions faites\n",
    "    nbpred   = []\n",
    "    # pour chaque playlist\n",
    "    for p in play_tst:\n",
    "        # si au moins deux chansons\n",
    "        if (len(p)>1):\n",
    "            # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "            seeds  = p[:np.min([5,len(p)-1])]\n",
    "            # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "            topred = p[np.min([5,len(p)-1]):]\n",
    "            # construction des suggestions 10 suggestions par morceaux a predire\n",
    "            prediction = neigh.kneighbors(vectors_tracks[seeds, :], 10*len(topred), return_distance=False)\n",
    "            \n",
    "            # filter first prediction since it is the track itself (distance is 0) UTIL ??\n",
    " \n",
    "            #prediction = predict(seeds,10*len(topred),vectors_tracks, metrics)\n",
    "            # comptage du nombre de morceaux présent dans nos suggestions\n",
    "            goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "            # stockage du nombre de predictions\n",
    "            nbpred.append(len(topred))\n",
    "    # proportions de morceux présents dans nos suggestions\n",
    "    return np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#braycurtis\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#minkowski\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#canberra\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#chebyshev\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dice\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hamming\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jaccard\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#kulsinski\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mahalanobis\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='mahalanobis')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rogerstanimoto\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='rogerstanimoto')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#russellrao\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='russellrao')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#seuclidean\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='seuclidean')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sokalmichener\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='sokalmichener')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sokalsneath\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='sokalsneath')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sqeuclidean\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='sqeuclidean')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#yule\n",
    "neigh = NearestNeighbors(5, algorithm='auto', metric='yule')\n",
    "neigh.fit(vectors_tracks)\n",
    "test_kneighbors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ici se termine le formidable travail de **Maxme**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
