{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des données de playlist\n",
    "import numpy as np\n",
    "data = np.load(\"resources/music_2.npy\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# récupération uniquement des identifiant de morceaux // suppression des identifiant d'artiste\n",
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de morceaux != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nombre d'occurence de chaque morceaux ?\n",
    "track_counts = dict((tracks[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtrage des morceaux très peu fréquents\n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 7, playlist)) for playlist in playlist_track]\n",
    "track_f = np.unique(np.concatenate(playlist_track_filter))\n",
    "Vt = len(track_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construction d'un dict id_morceaux id [0,Vt]\n",
    "track_dict = dict((track_f[i],i) for i in range(0, Vt))\n",
    "# conversion des playlisat en liste d'entier\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import de Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-paramètres de word2vec :\n",
    "# dimension de l'espace latent\n",
    "vector_dim = 50\n",
    "# taille de la fenêtre de voisinage\n",
    "window_width = 5\n",
    "# sur-échantillonage des exemples négatifs\n",
    "neg_sample = 4.\n",
    "# taille des mini-batch\n",
    "min_batch_size = 50\n",
    "# coeff pour la loi de tirage des exemple negatif\n",
    "samp_coef = -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comptage du nombre d'occurences des morceaux dans les playlist filtrées\n",
    "tracks_counts_f = dict((track_f[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track_filter:\n",
    "    for t in p:\n",
    "        tracks_counts_f[t]=tracks_counts_f[t]+1;\n",
    "# construction de la table de tirage des morceaux pour les exmeple negatif en utilisant ces fréquences\n",
    "spt_tracks=np.array(list(map(lambda a:tracks_counts_f[a],track_f)),np.float)\n",
    "sptn_tracks=np.power(spt_tracks,samp_coef)\n",
    "sptn_tracks=sptn_tracks/np.sum(sptn_tracks)\n",
    "sptn_tracks=np.cumsum(np.sort(sptn_tracks)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2inl2/efurreed/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# construction du réseau word2vec\n",
    "\n",
    "# entrée deux entier (couple de morceaux)\n",
    "input_target_t = Input((1,), dtype='int32')\n",
    "input_context_t = Input((1,), dtype='int32')\n",
    "\n",
    "# définition de l'embeding\n",
    "embedding_t_t = Embedding(Vt, vector_dim, input_length=1, name='embedding_t')\n",
    "# projection du premier morceau\n",
    "target_t = embedding_t_t(input_target_t)\n",
    "target_t = Reshape((vector_dim, 1))(target_t)\n",
    "\n",
    "# projection du second morceaux\n",
    "context_t = embedding_t_t(input_context_t)\n",
    "context_t = Reshape((vector_dim, 1))(context_t)\n",
    "\n",
    "# calcul de la sortie\n",
    "dot_product_t = Dot(axes=0)([target_t, context_t])\n",
    "dot_product_t = Reshape((1,))(dot_product_t)\n",
    "output_t = Dense(1, activation='sigmoid',name=\"classif\")(dot_product_t)\n",
    "\n",
    "# definition du modèle\n",
    "SkipGram_t = Model(inputs=[input_target_t, input_context_t], outputs=output_t)\n",
    "SkipGram_t.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# définition du générateur de couple de morceaux (y=0 <-> aléatoire, y=1 <-> proche dans une playlist)\n",
    "import random\n",
    "def track_ns_generator(corpus_num,nbm):\n",
    "    while 1:\n",
    "        Data=[]\n",
    "        Labels=[]\n",
    "        for i, doc in enumerate(random.sample(corpus_num,nbm)):\n",
    "            data, labels = skipgrams(sequence=doc, vocabulary_size=Vt, window_size=window_width, negative_samples=neg_sample,sampling_table=sptn_tracks)\n",
    "            if (len(data)>0):\n",
    "                Data.append(np.array(data, dtype=np.int32))\n",
    "                Labels.append(np.array(labels, dtype=np.int32))\n",
    "        Data=np.concatenate(Data)\n",
    "        Labels=np.concatenate(Labels)\n",
    "        x=[Data[:,0],Data[:,1]]\n",
    "        y=Labels\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble de test et d'apprentissage\n",
    "index_tst = np.random.choice(100000,10000)\n",
    "index_app  = np.setdiff1d(range(100000),index_tst)\n",
    "\n",
    "play_app   = [corpus_num_track[i] for i in index_app]\n",
    "play_tst  = [corpus_num_track[i] for i in index_tst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2inl2/efurreed/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6655\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6187\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.5830\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.5371\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4857\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4849\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4860\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4839\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4804\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4821\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4795\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4833\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4790\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4834\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4802\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4800\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4746\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 0.4806\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.4753\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 0.4803\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4768\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4790\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4719\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4779\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4719\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4721\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4696\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4762\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4773\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4744\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4665\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4625\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4621\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4666\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4624\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4584\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4582\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4661\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4601\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4680\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4574\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4531\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4554\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.4564\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4519\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4530\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.4515\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4580\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.4499\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4595\n"
     ]
    }
   ],
   "source": [
    "# apprentissage\n",
    "hist=SkipGram_t.fit_generator(track_ns_generator(play_app,min_batch_size),200,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# récupérations des positions des morceaux dans l'espace de projection\n",
    "vectors_tracks = SkipGram_t.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction retpournant les indices des s plus proches voisins des seeds dans la matrice X\n",
    "# a vous de jouer avec pairwise_distances, np.min, np.argsort,...\n",
    "def predict(seeds,s,X):\n",
    "    V = X.shape[0]\n",
    "    others = np.setdiff1d(range(V),seeds)\n",
    "    D = pairwise_distances(X[seeds,:],X[others,:],'cosine')\n",
    "    return others[np.argsort(np.min(D,0))[:s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 424, 1535, 2678, 1960])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemple pour 4 suggestions avec les 2 premiers morceaux en seeds \n",
    "pr=predict([0,1],4,vectors_tracks)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d611b2a4798d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtopred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# construction des suggestions 10 suggestions par morceaux a predire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors_tracks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# comptage du nombre de morceaux présent dans nos suggestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgoodpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# estimation des performances\n",
    "# hit@10\n",
    "# nombre de bonne prediction\n",
    "goodpred = []\n",
    "# nombre de predictions faites\n",
    "nbpred   = []\n",
    "# pour chaque playlist\n",
    "for p in play_tst:\n",
    "    # si au moins deux chansons\n",
    "    if (len(p)>1):\n",
    "        # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "        seeds  = p[:np.min([5,len(p)-1])]\n",
    "        # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "        topred = p[np.min([5,len(p)-1]):]\n",
    "        # construction des suggestions 10 suggestions par morceaux a predire\n",
    "        prediction = predict(seeds,10*len(topred),vectors_tracks)\n",
    "        # comptage du nombre de morceaux présent dans nos suggestions\n",
    "        goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "        # stockage du nombre de predictions\n",
    "        nbpred.append(len(topred))\n",
    "# proportions de morceux présents dans nos suggestions\n",
    "hitat10 = np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitat10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of the metrics for pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pairwise(metrics='euclidean'):\n",
    "    # nombre de bonne prediction\n",
    "    goodpred = []\n",
    "    # nombre de predictions faites\n",
    "    nbpred   = []\n",
    "    # pour chaque playlist\n",
    "    for p in play_tst:\n",
    "        # si au moins deux chansons\n",
    "        if (len(p)>1):\n",
    "            # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "            seeds  = p[:np.min([5,len(p)-1])]\n",
    "            # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "            topred = p[np.min([5,len(p)-1]):]\n",
    "            # construction des suggestions 10 suggestions par morceaux a predire\n",
    "            prediction = predict(seeds,10*len(topred),vectors_tracks, metrics)\n",
    "            # comptage du nombre de morceaux présent dans nos suggestions\n",
    "            goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "            # stockage du nombre de predictions\n",
    "            nbpred.append(len(topred))\n",
    "    # proportions de morceux présents dans nos suggestions\n",
    "    return np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_VALID_METRICS = ['euclidean', 'cosine', 'manhattan']\n",
    "hitat10_results = dict((metric, test_pairwise(metric)) for metric in _VALID_METRICS)\n",
    "hitat10_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faire\n",
    "\n",
    "- faire quelque graphique sen particulier pour discuter le choix de n'avoir garder que les morceaux présents dans plus de sept playlists\n",
    "- coder la fonction predict permetant de trouver les morceaux les plus proches des seeds (dans un premier temps de manière simple en utilisant la fonction pairwise_dist de sklearn)\n",
    "- tester l'influence des différents type de distance sur les les performances en terme de hit@10\n",
    "- vous pourrez ensuite essayé d'optimiser cette recherche https://scikit-learn.org/stable/modules/neighbors.html\n",
    "- faites varier un hyper-paramètres sur une plage raisonable \n",
    "- faire un graphique de hit@10 en fonction des valeurs de l'hyperparamètre\n",
    "- faire de même avec un second\n",
    "- proposer des valeures finales pour les hyper-paramètres\n",
    "- joindre avec les meta-données, url des morceaux ....\n",
    "- exporter // faire le liens avec le front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aide jointure\n",
    "import pandas as pd\n",
    "tr_meta=pd.read_csv(\"resources/./Tracks_V2.csv\")\n",
    "jdf = pd.DataFrame({\"id\":track_f,\"index\":range(Vt)})\n",
    "jdf[\"deezer_id\"]=jdf[\"id\"].apply(lambda x: float(x.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta = tr_meta.merge(jdf, left_on=\"id\",right_on=\"deezer_id\")\n",
    "trj_meta.set_index(\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of predict_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aide predict_opt\n",
    "#créer un kd-tree\n",
    "from sklearn.neighbors import KDTree\n",
    "from operator import itemgetter\n",
    "\n",
    "kdt = KDTree(vectors_tracks, leaf_size=30, metric='euclidean')\n",
    "\n",
    "#fonction de recherche a compléter\n",
    "#vérifer la cohérences des résulats avec predict\n",
    "# TODO : enlever les premiers voisins (ils sont à une distance 0 car il s'agit des points eux-memes) \n",
    "def predict_opt(seeds,s,X,kdt):\n",
    "    V = X.shape[0]\n",
    "    seeds_size = len(seeds)\n",
    "    others = np.setdiff1d(range(V),seeds)\n",
    "    \n",
    "    dist, ind = kdt.query(X[seeds , :], k = s, sort_results = True)\n",
    "    dist_ind_list = np.concatenate(np.dstack((dist, ind)))\n",
    "    dist_ind_list = list(map(lambda x : tuple(x), dist_ind_list))\n",
    "    sorted_dist_ind_list = sorted(dist_ind_list, key=itemgetter(0))[seeds_size : s + seeds_size]\n",
    "\n",
    "    neigh = list(map(lambda x : x[1], sorted_dist_ind_list))\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vérification de la cohérences des résultats des suggestion\n",
    "pr=predict([0,1],10,vectors_tracks)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr=predict_opt([0,1],10,vectors_tracks, kdt)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimation des performances\n",
    "# hit@10\n",
    "# nombre de bonne prediction\n",
    "goodpred = []\n",
    "# nombre de predictions faites\n",
    "nbpred   = []\n",
    "# pour chaque playlist\n",
    "for p in play_tst:\n",
    "    # si au moins deux chansons\n",
    "    if (len(p)>1):\n",
    "        # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "        seeds  = p[:np.min([5,len(p)-1])]\n",
    "        # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "        topred = p[np.min([5,len(p)-1]):]\n",
    "        # construction des suggestions 10 suggestions par morceaux a predire\n",
    "        prediction = predict_opt(seeds,10*len(topred),vectors_tracks,kdt)\n",
    "        # comptage du nombre de morceaux présent dans nos suggestions\n",
    "        goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "        # stockage du nombre de predictions\n",
    "        nbpred.append(len(topred))\n",
    "# proportions de morceux présents dans nos suggestions\n",
    "hitat10 = np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta.sort_values(by=['rank'],ascending=False)[\"title\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# les voisins de i will survive ?\n",
    "b=predict([9152],4,vectors_tracks)\n",
    "trj_meta.loc[b,\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# un peu de musique\n",
    "import IPython\n",
    "IPython.display.Audio(trj_meta.loc[19030,\"preview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
