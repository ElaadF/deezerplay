{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des données de playlist\n",
    "import numpy as np\n",
    "data = np.load(\"../resources/music_2.npy\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# récupération uniquement des identifiant de morceaux // suppression des identifiant d'artiste\n",
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338509"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de morceaux != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nombre d'occurence de chaque morceaux ?\n",
    "track_counts = dict((tracks[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtrage des morceaux très peu fréquents\n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 7, playlist)) for playlist in playlist_track]\n",
    "track_f = np.unique(np.concatenate(playlist_track_filter))\n",
    "Vt = len(track_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construction d'un dict id_morceaux id [0,Vt]\n",
    "track_dict = dict((track_f[i],i) for i in range(0, Vt))\n",
    "# conversion des playlisat en liste d'entier\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import de Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-paramètres de word2vec :\n",
    "# dimension de l'espace latent\n",
    "vector_dim = 50\n",
    "# taille de la fenêtre de voisinage\n",
    "window_width = 5\n",
    "# sur-échantillonage des exemples négatifs\n",
    "neg_sample = 4.\n",
    "# taille des mini-batch\n",
    "min_batch_size = 50\n",
    "# coeff pour la loi de tirage des exemple negatif\n",
    "samp_coef = -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comptage du nombre d'occurences des morceaux dans les playlist filtrées\n",
    "tracks_counts_f = dict((track_f[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track_filter:\n",
    "    for t in p:\n",
    "        tracks_counts_f[t]=tracks_counts_f[t]+1;\n",
    "# construction de la table de tirage des morceaux pour les exmeple negatif en utilisant ces fréquences\n",
    "spt_tracks=np.array(list(map(lambda a:tracks_counts_f[a],track_f)),np.float)\n",
    "sptn_tracks=np.power(spt_tracks,samp_coef)\n",
    "sptn_tracks=sptn_tracks/np.sum(sptn_tracks)\n",
    "sptn_tracks=np.cumsum(np.sort(sptn_tracks)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construction du réseau word2vec\n",
    "\n",
    "# entrée deux entier (couple de morceaux)\n",
    "input_target_t = Input((1,), dtype='int32')\n",
    "input_context_t = Input((1,), dtype='int32')\n",
    "\n",
    "# définition de l'embeding\n",
    "embedding_t_t = Embedding(Vt, vector_dim, input_length=1, name='embedding_t')\n",
    "# projection du premier morceau\n",
    "target_t = embedding_t_t(input_target_t)\n",
    "target_t = Reshape((vector_dim, 1))(target_t)\n",
    "\n",
    "# projection du second morceaux\n",
    "context_t = embedding_t_t(input_context_t)\n",
    "context_t = Reshape((vector_dim, 1))(context_t)\n",
    "\n",
    "# calcul de la sortie\n",
    "dot_product_t = Dot(axes=0)([target_t, context_t])\n",
    "dot_product_t = Reshape((1,))(dot_product_t)\n",
    "output_t = Dense(1, activation='sigmoid',name=\"classif\")(dot_product_t)\n",
    "\n",
    "# definition du modèle\n",
    "SkipGram_t = Model(inputs=[input_target_t, input_context_t], outputs=output_t)\n",
    "SkipGram_t.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# définition du générateur de couple de morceaux (y=0 <-> aléatoire, y=1 <-> proche dans une playlist)\n",
    "import random\n",
    "def track_ns_generator(corpus_num,nbm):\n",
    "    while 1:\n",
    "        Data=[]\n",
    "        Labels=[]\n",
    "        for i, doc in enumerate(random.sample(corpus_num,nbm)):\n",
    "            data, labels = skipgrams(sequence=doc, vocabulary_size=Vt, window_size=window_width, negative_samples=neg_sample,sampling_table=sptn_tracks)\n",
    "            if (len(data)>0):\n",
    "                Data.append(np.array(data, dtype=np.int32))\n",
    "                Labels.append(np.array(labels, dtype=np.int32))\n",
    "        Data=np.concatenate(Data)\n",
    "        Labels=np.concatenate(Labels)\n",
    "        x=[Data[:,0],Data[:,1]]\n",
    "        y=Labels\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble de test et d'apprentissage\n",
    "index_tst = np.random.choice(100000,10000)\n",
    "index_app  = np.setdiff1d(range(100000),index_tst)\n",
    "\n",
    "play_app   = [corpus_num_track[i] for i in index_app]\n",
    "play_tst  = [corpus_num_track[i] for i in index_tst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.6657\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.6177\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.5563\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4887\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4827\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4837\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4819\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4862\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4820\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4833\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4852\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4853\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4770\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4775\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4773\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4770\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4818\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4768\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4821\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4801\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4777\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4722\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4698\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4707\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4723\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4600\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4578\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4578\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4584\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4601\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4598\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4600\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4620\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.4620\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4589\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.4571\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.4591\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4606\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.4630\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.4590\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4631\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4648\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4598\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.4550\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.4545\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.4553\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4551\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4485\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.4469\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4467\n"
     ]
    }
   ],
   "source": [
    "# apprentissage\n",
    "hist=SkipGram_t.fit_generator(track_ns_generator(play_app,min_batch_size),200,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# récupérations des positions des morceaux dans l'espace de projection\n",
    "vectors_tracks = SkipGram_t.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction retpournant les indices des s plus proches voisins des seeds dans la matrice X\n",
    "# a vous de jouer avec pairwise_distances, np.min, np.argsort,...\n",
    "def predict(seeds,s,X, metric='euclidean'):\n",
    "    V = X.shape[0]\n",
    "    others = np.setdiff1d(range(V),seeds)\n",
    "    D = pairwise_distances(X[seeds,:],X[others,:],metric)\n",
    "    return others[np.argsort(np.min(D,0))[:s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([893,  66, 504, 787])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemple pour 4 suggestions avec les 2 premiers morceaux en seeds \n",
    "pr=predict([0,1],4,vectors_tracks)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-df43bc6b6c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtopred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# construction des suggestions 10 suggestions par morceaux a predire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors_tracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# comptage du nombre de morceaux présent dans nos suggestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mgoodpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-08ae44513a4d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seeds, s, X)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mothers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2inl2/mthouv02/.local/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2inl2/mthouv02/.local/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2inl2/mthouv02/.local/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \"\"\"\n\u001b[1;32m    549\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2inl2/mthouv02/.local/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m--> 905\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/2inl2/mthouv02/.local/lib/python3.5/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# estimation des performances\n",
    "# hit@10\n",
    "# nombre de bonne prediction\n",
    "goodpred = []\n",
    "# nombre de predictions faites\n",
    "nbpred   = []\n",
    "# pour chaque playlist\n",
    "for p in play_tst:\n",
    "    # si au moins deux chansons\n",
    "    if (len(p)>1):\n",
    "        # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "        seeds  = p[:np.min([5,len(p)-1])]\n",
    "        # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "        topred = p[np.min([5,len(p)-1]):]\n",
    "        # construction des suggestions 10 suggestions par morceaux a predire\n",
    "        prediction = predict(seeds,10*len(topred),vectors_tracks)\n",
    "        # comptage du nombre de morceaux présent dans nos suggestions\n",
    "        goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "        # stockage du nombre de predictions\n",
    "        nbpred.append(len(topred))\n",
    "# proportions de morceux présents dans nos suggestions\n",
    "hitat10 = np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitat10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of the metrics for pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pairwise(metrics='euclidean'):\n",
    "    # nombre de bonne prediction\n",
    "    goodpred = []\n",
    "    # nombre de predictions faites\n",
    "    nbpred   = []\n",
    "    # pour chaque playlist\n",
    "    for p in play_tst:\n",
    "        # si au moins deux chansons\n",
    "        if (len(p)>1):\n",
    "            # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "            seeds  = p[:np.min([5,len(p)-1])]\n",
    "            # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "            topred = p[np.min([5,len(p)-1]):]\n",
    "            # construction des suggestions 10 suggestions par morceaux a predire\n",
    "            prediction = predict(seeds,10*len(topred),vectors_tracks, metrics)\n",
    "            # comptage du nombre de morceaux présent dans nos suggestions\n",
    "            goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "            # stockage du nombre de predictions\n",
    "            nbpred.append(len(topred))\n",
    "    # proportions de morceux présents dans nos suggestions\n",
    "    return np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_VALID_METRICS = ['euclidean', 'cosine', 'manhattan']\n",
    "hitat10_results = dict((metric, test_pairwise(metric)) for metric in _VALID_METRICS)\n",
    "hitat10_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar chart for the results of hitat10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hitat10_results' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0aa87458e5f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msorted_hitat10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhitat10_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msorted_hitat10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hitat10_results' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "sorted_hitat10 = sorted(hitat10_results.items(), key=operator.itemgetter(1))\n",
    "sorted_hitat10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Dataset\n",
    "values = []\n",
    "labels = []\n",
    "for item in sorted_hitat10:\n",
    "    values.append(item[1])\n",
    "    labels.append(item[0])\n",
    "    \n",
    "# Create bars and choose color\n",
    "y_pos = np.arange(len(labels))\n",
    "plt.bar(y_pos, values, color = (0.5,0.1,0.5,0.6))\n",
    "\n",
    "# Add title and axis names\n",
    "plt.title('Hitat10 results for different metrics')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('score')\n",
    " \n",
    "# Limits for the Y axis\n",
    "plt.ylim(0, np.max(values) * 1.5)\n",
    " \n",
    "# Create names\n",
    "plt.xticks(y_pos, labels)\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faire\n",
    "\n",
    "- faire quelque graphique sen particulier pour discuter le choix de n'avoir garder que les morceaux présents dans plus de sept playlists\n",
    "- coder la fonction predict permetant de trouver les morceaux les plus proches des seeds (dans un premier temps de manière simple en utilisant la fonction pairwise_dist de sklearn)\n",
    "- tester l'influence des différents type de distance sur les les performances en terme de hit@10\n",
    "- vous pourrez ensuite essayé d'optimiser cette recherche https://scikit-learn.org/stable/modules/neighbors.html\n",
    "- faites varier un hyper-paramètres sur une plage raisonable \n",
    "- faire un graphique de hit@10 en fonction des valeurs de l'hyperparamètre\n",
    "- faire de même avec un second\n",
    "- proposer des valeures finales pour les hyper-paramètres\n",
    "- joindre avec les meta-données, url des morceaux ....\n",
    "- exporter // faire le liens avec le front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aide jointure\n",
    "import pandas as pd\n",
    "tr_meta=pd.read_csv(\"resources/./Tracks_V2.csv\")\n",
    "jdf = pd.DataFrame({\"id\":track_f,\"index\":range(Vt)})\n",
    "jdf[\"deezer_id\"]=jdf[\"id\"].apply(lambda x: float(x.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta = tr_meta.merge(jdf, left_on=\"id\",right_on=\"deezer_id\")\n",
    "trj_meta.set_index(\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of predict_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aide predict_opt\n",
    "#créer un kd-tree\n",
    "from sklearn.neighbors import KDTree\n",
    "from operator import itemgetter\n",
    "\n",
    "kdt = KDTree(vectors_tracks, leaf_size=30, metric='euclidean')\n",
    "\n",
    "#fonction de recherche a compléter\n",
    "#vérifer la cohérences des résulats avec predict\n",
    "# TODO : enlever les premiers voisins (ils sont à une distance 0 car il s'agit des points eux-memes) \n",
    "def predict_opt(seeds,s,X,kdt):\n",
    "    V = X.shape[0]\n",
    "    seeds_size = len(seeds)\n",
    "    others = np.setdiff1d(range(V),seeds)\n",
    "    \n",
    "    dist, ind = kdt.query(X[seeds , :], k = s + seeds_size)\n",
    "    dist_ind_list = np.concatenate(np.dstack((dist, ind)))\n",
    "    dist_ind_list2 = list(map(lambda x : tuple(x), dist_ind_list))\n",
    "    sorted_dist_ind_list = sorted(dist_ind_list2, key=itemgetter(0))[seeds_size : (s + seeds_size)]\n",
    "\n",
    "    neigh = list(map(lambda x : x[1], sorted_dist_ind_list))\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 893,   66,  504,  787,  483,  789, 1452, 1828, 1383, 1546, 1436,\n",
       "       3311, 1709, 2268, 1547, 2385, 2956, 1545, 1784, 1384, 1840, 2847,\n",
       "        446, 3043, 1976])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vérification de la cohérences des résultats des suggestion\n",
    "pr=predict([0,1],25, vectors_tracks, 'euclidean')\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[893.0,\n",
       " 66.0,\n",
       " 504.0,\n",
       " 787.0,\n",
       " 483.0,\n",
       " 789.0,\n",
       " 1452.0,\n",
       " 1828.0,\n",
       " 1383.0,\n",
       " 1546.0,\n",
       " 1436.0,\n",
       " 3311.0,\n",
       " 1709.0,\n",
       " 2268.0,\n",
       " 1547.0,\n",
       " 2385.0,\n",
       " 2956.0,\n",
       " 1545.0,\n",
       " 1784.0,\n",
       " 1384.0,\n",
       " 1840.0,\n",
       " 2847.0,\n",
       " 446.0,\n",
       " 3043.0,\n",
       " 1976.0]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2=predict_opt([0,1],25,vectors_tracks, kdt)\n",
    "pr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimation des performances\n",
    "# hit@10\n",
    "# nombre de bonne prediction\n",
    "goodpred = []\n",
    "# nombre de predictions faites\n",
    "nbpred   = []\n",
    "# pour chaque playlist\n",
    "for p in play_tst:\n",
    "    # si au moins deux chansons\n",
    "    if (len(p)>1):\n",
    "        # recuperations des seeds 5 premiers morceaux ou moins si la playlist contient moins de 5 morceaux\n",
    "        seeds  = p[:np.min([5,len(p)-1])]\n",
    "        # recuperations de la suite de la playlist que nous allons comparer à nos suggestions\n",
    "        topred = p[np.min([5,len(p)-1]):]\n",
    "        # construction des suggestions 10 suggestions par morceaux a predire\n",
    "        prediction = predict_opt(seeds,10*len(topred),vectors_tracks,kdt)\n",
    "        # comptage du nombre de morceaux présent dans nos suggestions\n",
    "        goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "        # stockage du nombre de predictions\n",
    "        nbpred.append(len(topred))\n",
    "# proportions de morceux présents dans nos suggestions\n",
    "hitat10 = np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hyper-parameters for KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing hyper-parameters 'leaf_size' for KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predict_opt(leaf_size = 10, metric = 'euclidean'):\n",
    "    \n",
    "    kdt = KDTree(vectors_tracks, leaf_size, metric)\n",
    "    # nombre de bonne prediction\n",
    "    goodpred = []\n",
    "    # nombre de predictions faites\n",
    "    nbpred   = []\n",
    "    # pour chaque playlist\n",
    "    for p in play_tst:\n",
    "        # si au moins deux chansons\n",
    "        if (len(p)>1):\n",
    "            seeds  = p[:np.min([5,len(p)-1])]\n",
    "            topred = p[np.min([5,len(p)-1]):]\n",
    "            \n",
    "            prediction = predict_opt(seeds,10*len(topred),vectors_tracks, kdt)\n",
    "            goodpred.append(len(np.intersect1d(prediction,topred)))\n",
    "            nbpred.append(len(topred))\n",
    "\n",
    "    return np.sum(goodpred)/np.sum(nbpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing hyper-parameter 'metric' for KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trj_meta.sort_values(by=['rank'],ascending=False)[\"title\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# les voisins de i will survive ?\n",
    "b=predict([9152],4,vectors_tracks)\n",
    "trj_meta.loc[b,\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# un peu de musique\n",
    "import IPython\n",
    "IPython.display.Audio(trj_meta.loc[19030,\"preview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
